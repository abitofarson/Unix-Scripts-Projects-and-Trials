#! /bin/gawk
#
# Project 10: Word Count awk Script
# Libby Wichman


{print tolower($0)} 
# -----------------
# R10_001_587259
# -----------------
# The above awk command converts each record read to all lower case letters.
# This may have to be tweaked because the requirements say this must be 
# done prior to the words being counted. 
# I know not to do it in the BEGIN block, as it is only executed once.

{
for (f = 1; f <= NF; f++ )
	{ 
	for (i = 1; i <= NF; i++ ) 
		{
		if ("$i" in uniquewords) 
			{ 
			uniquewords["$i"] += 1 
			} 
		else 
			{
			 uniquewords["$i"] = 1  
			}	
		}
	}
}
# -----------------
# R10_002_587259
# -----------------
# The above treats all words as unique if they do not match exactly.
# -----------------
# R10_003_587259
# -----------------
# The above puts all the unique words into an associative array that
# counts the number of instances of those words.


# -----------------
# R10_004_587259
# -----------------
# The asorti fuction was added to END so the indices would be displayed
# in the organized output of data. 


END{
n = asorti(uniquewords, dest)
for (x = 1; x <= n; x++)
{
	printf "%-5s\t%20s\n", "Index", "Word Count"
	printf "%s\n", "         1         2        3         4"
	printf "%s\n", "1234567890123456789012345678901234567890"
	{
		for( x in dest[x] )
			{ 
			printf "%-5s%20s%6s\n", x, dest[x], uniquewords[dest[x]]
			} 
	}
}
}
# ----------------- 
# R10_005_587259
# -----------------
# The designated headings are printed out at the top.
# This is followed by data in three columns. The first
# colomn is the index number(?), the second is the word itself
# and the third is the number of times the word occured in
# the input file.

# -----------------
# R10_006_587259
# -----------------
# On the command line, the output of gawk will be redireted
# to append to the file p10_s1_out.txt.
